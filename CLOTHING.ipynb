{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy\nimport re\nimport string\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nfrom wordcloud import WordCloud, STOPWORDS\n\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import MultinomialNB\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer \nfrom nltk.stem import PorterStemmer, LancasterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nimport nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\n#from nltk.corpus import stopwords\nimport string\nfrom nltk.tokenize import RegexpTokenizer\nimport statsmodels.api as sm\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom nltk.stem.porter import PorterStemmer\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, SimpleRNN\n\nfrom textblob import TextBlob\nimport warnings\nwarnings.filterwarnings('ignore') \n\nfrom IPython.display import Image\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing = pd.read_csv(\"../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\", index_col=0)\nprint(clothing.shape)\nclothing.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Checking for Missing Values\nclothing.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nplt.figure(figsize= (14,5))\nsns.distplot(clothing['Age'], hist_kws=dict(edgecolor=\"k\")).set_title(\"Distribution of Age\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11,5)})\nplt.hist(clothing.Age, bins=40)\nplt.xlabel('Age')\nplt.ylabel('Reviews')\nplt.title('Number of Reviews per Age');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11,6)})\nsns.boxplot(x = 'Rating', y = 'Age', data = clothing)\nplt.title('Rating Distribution per Age');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = clothing.groupby(by=['Department Name'],as_index=False).count().sort_values(by='Class Name',ascending=False)\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=z['Department Name'],y=z['Class Name'], data=z)\nplt.xlabel(\"Department Name\")\nplt.ylabel(\"Count\")\nplt.title(\"Counts Vs Department Name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = clothing.groupby(by=['Division Name'],as_index=False).count().sort_values(by='Class Name',ascending=False)\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=w['Division Name'],y=w['Class Name'], data=w)\nplt.xlabel(\"Division Name\")\nplt.ylabel(\"Count\")\nplt.title(\"Counts Vs Division Name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  The Product Rating Distribution\nplt.figure(figsize= (14,5))\nax=sns.countplot(x='Rating', data=clothing)\nax.set_title(\"Distribution of Ratings\", fontsize=14)\n\nx=clothing['Rating'].value_counts()\n\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = clothing[\"Rating\"].value_counts()\nfig, ax = plt.subplots(figsize=(10, 6))\nplt.bar(clothing[\"Rating\"].unique(),h)\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Counts\")\nplt.title(\"Histogram of Ratings\")\nplt.figure(figsize=(8,4))\nax.grid(True)\nplt.rcParams['axes.axisbelow'] = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Number of Reviews per Product Category\nplt.figure(figsize= (14,5))\nax=sns.countplot(x='Department Name', data=clothing, order = clothing['Department Name'].value_counts().index)\nax.set_title(\"Reviews per Department\", fontsize=14)\nax.set_ylabel(\"# of Reviews\", fontsize=12)\nax.set_xlabel(\"Department\", fontsize=12)\n\nx=clothing['Department Name'].value_counts()\n\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11,6)})\nsns.boxplot(x = 'Rating', y = 'Age', data = clothing)\nplt.title('Rating Distribution per Age');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Distribution of Class\nax = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax = plt.xticks(rotation=45)\nax = sns.countplot(clothing['Class Name'])\nax = plt.title(\"Reviews in Each Class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Rate of Recommendations\nrecommended = clothing[clothing['Recommended IND']==1]\nnot_recommended = clothing[clothing['Recommended IND']==0]\n\nax0 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax0 = plt.xticks(rotation=45)\nax0 = sns.countplot(recommended['Class Name'], color=\"red\", alpha = 0.8, label = \"Recommended\")\nax0 = sns.countplot(not_recommended['Class Name'], color=\"green\", alpha = 0.8, label = \"Not Recommended\")\nax0 = plt.title(\"Recommended Items in Each Class\")\nax0 = plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax1 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax1 = plt.xticks(rotation=45)\nax1 = sns.boxplot(x=\"Class Name\", y=\"Rating\", data=clothing)\nax1 = plt.title('Rating Distribution per Class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Most Popular Item\nfig = plt.figure(figsize=(14, 9))\nplt.xticks(rotation=45)\nplt.xlabel('Item ID')\nplt.ylabel('Popularity')\nplt.title(\"Top 50 Popular Items\")\nclothing['Clothing ID'].value_counts()[:50].plot(kind='bar');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Correlation Plot of Department,Division and Class Against Each Other\nsns.heatmap(pd.crosstab(clothing['Class Name'], \n        clothing[\"Department Name\"]),\n            annot=True,fmt='g', cmap=\"Pastel2_r\")\nplt.title(\"Class Name Count Vs Department Name\",fontsize=20,fontweight='bold')\nplt.show()\n\nsns.heatmap(pd.crosstab(clothing['Class Name'], clothing[\"Division Name\"]),\n            annot=True,fmt='g', cmap=\"Pastel1\")\nplt.title(\"Class Name Count Vs Division Name\",fontsize=20,fontweight='bold')\n\nplt.show()\n\nsns.heatmap(pd.crosstab(clothing['Department Name'], clothing[\"Division Name\"]),\n            annot=True,fmt='g', cmap=\"Pastel1_r\")\nplt.title(\"Department Name Count Vs Division Name\",fontsize=20,fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  The Amount of Missing Values per Feature\nsns.set(rc={'figure.figsize':(11,4)})\npd.isnull(clothing).sum().plot(kind='bar')\nplt.ylabel('Number of Missing Values')\nplt.title('Missing Values per Feature');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing.dropna(subset=['Review Text'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Building Some WordClouds\ndef clean_data(text):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n    words = letters_only.lower().split()                            \n    return( \" \".join( words ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords= set(STOPWORDS)|{'skirt', 'blouse','dress','sweater', 'shirt','bottom', 'pant', 'pants' 'jean', 'jeans','jacket', 'top', 'dresse', 'material', 'while', 'black', 'fabric', 'color', 'order', 'wear'}\n\ndef create_cloud(rating):\n    x= [i for i in rating]\n    y= ' '.join(x)\n    cloud = WordCloud(background_color='white',width=1600, height=800,max_words=100,stopwords = stopwords).generate(y)\n    plt.figure(figsize=(15,7.5))\n    plt.axis('off')\n    plt.imshow(cloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Rating = 1 Top Words\nrating1 = clothing[clothing['Rating']==1]['Review Text'].apply(clean_data)\ncreate_cloud(rating1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Rating = 2 Top Words\nrating2 = clothing[clothing['Rating']==2]['Review Text'].apply(clean_data)\ncreate_cloud(rating2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Rating = 3 Top Words\nrating3 = clothing[clothing['Rating']==3]['Review Text'].apply(clean_data)\ncreate_cloud(rating3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Rating = 4 Top Words\nrating4 = clothing[clothing['Rating']==4]['Review Text'].apply(clean_data)\ncreate_cloud(rating1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Rating = 5 Top Words\nrating5 = clothing[clothing['Rating']==5]['Review Text'].apply(clean_data)\ncreate_cloud(rating1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing.loc[(clothing.Rating==1) & (clothing['Recommended IND']==1)]['Review Text'].iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing.loc[(clothing.Rating==5) & (clothing['Recommended IND']==0)]['Review Text'].iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Test Features - Preprocessing \n#  Dropping Punctuation\nstring.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def punctuation_removal(messy_string):\n    clean_list = [char for char in messy_string if char not in string.punctuation]\n    clean_string = ''.join(clean_list)\n    return clean_string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing['Review Text'] = clothing['Review Text'].apply(punctuation_removal)\nclothing['Review Text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  The Positiveness or Negativeness of the Reviews are mostly reflected by Verbs & Adjectives\ndef adj_collector(review_string):\n    new_string=[]\n    review_string = word_tokenize(review_string)\n    tup_word = nltk.pos_tag(review_string)\n    for tup in tup_word:\n        if 'VB' in tup[1] or tup[1]=='JJ':  #  Adjectives  &  Verbs\n            new_string.append(tup[0])  \n    return ' '.join(new_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing['Review Text'] = clothing['Review Text'].apply(adj_collector)\nclothing['Review Text'].head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Stopwords\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nstop.append(\"i'm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Punctuation Removal of Stopwords\nstop_words = []\n\nfor item in stop: \n    new_item = punctuation_removal(item)\n    stop_words.append(new_item) \nprint(stop_words[::12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Adding Clothing Stopwords\n#  Same as the Stopwords we defined in building the WordCloud\nclothing_list =['dress', 'top','sweater','shirt', 'blouse', 'pant', 'pants',\n               'skirt','material', 'white', 'black', 'bottom', 'jacket',\n              'jean', 'jeans', 'fabric', 'color', 'order', 'wear', 'dresse']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stopwords_removal(messy_str):\n    messy_str = word_tokenize(messy_str)\n    return [word.lower() for word in messy_str \n            if word.lower() not in stop_words and word.lower() not in clothing_list ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing['Review Text'] = clothing['Review Text'].apply(stopwords_removal)\nclothing['Review Text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clothing['Review Text'][762]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clothing['Review Text'][1033])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Removing All Numbers Including Size, Weight etc.\ndef drop_numbers(list_text):\n    list_text_new = []\n    for i in list_text:\n        if not re.search('\\d', i):\n            list_text_new.append(i)\n    return ' '.join(list_text_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing['Review Text'] = clothing['Review Text'].apply(drop_numbers)\nclothing['Review Text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clothing['Review Text'][3922])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clothing['Review Text'][762]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Stemming\nporter = PorterStemmer()\n\nclothing['Review Text'] = clothing['Review Text'].apply(lambda x: x.split())\nclothing['Review Text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stem_update(text_list):\n    text_list_new = []\n    for word in text_list:\n        word = porter.stem(word)\n        text_list_new.append(word) \n    return text_list_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing['Review Text'] = clothing['Review Text'].apply(stem_update)\nclothing['Review Text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clothing['Review Text'] = clothing['Review Text'].apply(lambda x: ' '.join(x))\nclothing['Review Text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clothing['Review Text'][3922])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clothing[\"Review Text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Sentiment Analysis\n# Pre-Processing\nSIA = SentimentIntensityAnalyzer()\n\n# Apply Model, Variable Creation\nclothing['Polarity Score'] = clothing[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['compound'])\nclothing['Neutral Score'] = clothing[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['neu'])\nclothing['Negative Score'] = clothing[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['neg'])\nclothing['Positive Score'] = clothing[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['pos'])\n\n# Convert 0 to 1 Decimal Score to a Categorical Variable\nclothing['Sentiment']=''\nclothing.loc[clothing['Polarity Score']>0,'Sentiment']='Positive'\nclothing.loc[clothing['Polarity Score']==0,'Sentiment']='Neutral'\nclothing.loc[clothing['Polarity Score']<0,'Sentiment']='Negative'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions = [\n    clothing['Sentiment'] == \"Positive\",\n    clothing['Sentiment'] == \"Negative\",\n    clothing['Sentiment'] == \"Neutral\"]\nchoices = [1,-1,0]\nclothing['label'] = np.select(conditions, choices)\nclothing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  RNN\nsamples = clothing[\"Review Text\"].tolist()\nmaxlen = 100 \nmax_words = 10000\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(samples)\nsequences = tokenizer.texts_to_sequences(samples)\nword_index = tokenizer.word_index\nprint('Found %s Unique Tokens.' % len(word_index))\ndata = pad_sequences(sequences, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = np.asarray(clothing[\"label\"].values)\nprint('Data Tensor Shape :', data.shape)\nprint('Label Tensor Shape :', labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = np.arange(clothing.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_samples = 11743\nvalidation_samples = 17614","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = data[:training_samples]\ny_train = labels[:training_samples]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = data[training_samples: validation_samples] \ny_val = labels[training_samples: validation_samples]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = data[validation_samples:]\ny_test = labels[validation_samples:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = pad_sequences(x_train, maxlen=maxlen)\nx_val = pad_sequences(x_val, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_RNN():\n    model = Sequential() \n    model.add(Embedding(max_words, 100, input_length=maxlen)) \n    model.add(SimpleRNN(32, return_sequences=True))\n    model.add(SimpleRNN(32)) \n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_RNN()\nmodel.summary()\nhistory_RNN = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"RNN.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history_RNN.history['acc']\nval_acc = history_RNN.history['val_acc']\nloss = history_RNN.history['loss']\nval_loss = history_RNN.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'b', label='Training Acc')\nplt.plot(epochs, val_acc, 'r', label='Validation Acc')\nplt.title('Training And Validation Accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training And Validation Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Simple Embedding Deep Neural Network\ndef build_model():\n    model = Sequential()\n    model.add(Embedding(max_words, 100, input_length=maxlen))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()\nhistory = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"DNN.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'b', label='Training Acc')\nplt.plot(epochs, val_acc, 'r', label='Validation Acc')\nplt.title('Training And Validation Accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training And Validation Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}